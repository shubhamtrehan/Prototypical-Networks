# -*- coding: utf-8 -*-
"""protoNet_tf2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17U8FJsOIsKvv0wzbz6iW-9qgtvDQPeoK
"""

import sys
sys.path.append("/home/szt/ProtoKD_Extension_October_2024/Experiments")

import tensorflow as tf
import multiprocessing as mp
import os
import cv2
import numpy as np
import matplotlib.pyplot as plt
from scipy import ndimage
from tensorflow.keras.layers import Input, Conv2D, Lambda, Dense, Flatten,MaxPooling2D, Activation
from tensorflow.keras.layers import BatchNormalization
from tensorflow.keras.models import Model, Sequential
from tensorflow.keras.regularizers import l2
from tensorflow.keras import backend as K
from tensorflow.keras.optimizers import SGD,Adam
import pickle

from models import *
from matplotlib.figure import Figure
from matplotlib.ticker import MaxNLocator

gpus = tf.config.experimental.list_physical_devices('GPU')
print(gpus)

if gpus:
  try:
    # Specify the GPU index here
    tf.config.experimental.set_visible_devices(gpus[3], 'GPU')
  except RuntimeError as e:
    # Visible devices must be set before GPUs have been initialized
    print(e)

"""<span style="font-size: 24px; color: yellow;"><b>Read Ova Data</b></span>"""

proto_samples_per_class = 20

# Define paths to your train and test directories
root = f"/media/DiskDrive1/Datasets/Ova_Dataset/Attempt4_data_version/{proto_samples_per_class}_Samples/ProtoNet_ProtoKD_data_version"
train_directory = f'{root}/train'
test_directory = f'{root}/test'

assert len(os.listdir(train_directory)) == len(os.listdir(test_directory))
all_classes = sorted(os.listdir(train_directory), key=str.lower)
print(all_classes)
print()
print("Total Number of Classes in this dataset",len(all_classes))

def read_category(category_directory_path, category_name):
    """
    Reads all images from a given category directory,
    applies rotations, and constructs labels including the
    category and rotation angle.
    """
    datax = []
    datay = []
    images = os.listdir(category_directory_path)
    for img in images:
        image_path = os.path.join(category_directory_path, img)
        image = cv2.imread(image_path)
        if image is None:
            print(f"Warning: Could not read image {image_path}. Skipping.")
            continue

        # Convert BGR to RGB
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        # Resize image to 28x28 pixels
        image = cv2.resize(image, (128, 128))
        # Rotations of image
        rotated_90 = ndimage.rotate(image, 90, reshape=False)
        rotated_180 = ndimage.rotate(image, 180, reshape=False)
        rotated_270 = ndimage.rotate(image, 270, reshape=False)
        # Collect images
        datax.extend((image, rotated_90, rotated_180, rotated_270))
        # Construct labels
        img_name = os.path.splitext(img)[0]  # Remove file extension
        datay.extend((
            category_name, #+ '_' + img_name + '_0',
            category_name, # + '_' + img_name + '_90',
            category_name, # + '_' + img_name + '_180',
            category_name, # + '_' + img_name + '_270'
        ))
    return np.array(datax), np.array(datay)

def read_images(base_directory):
    """
    Reads all categories from the base_directory
    Uses multiprocessing to decrease the reading time
    """
    datax_list = []
    datay_list = []
    categories = [d for d in os.listdir(base_directory) if os.path.isdir(os.path.join(base_directory, d))]
    pool = mp.Pool(mp.cpu_count())
    results = []
    for category in categories:
        category_directory_path = os.path.join(base_directory, category)
        result = pool.apply_async(read_category, args=(category_directory_path, category))
        results.append(result)
    pool.close()
    pool.join()
    for result in results:
        category_datax, category_datay = result.get()
        datax_list.append(category_datax)
        datay_list.append(category_datay)
    datax = np.vstack(datax_list)
    datay = np.concatenate(datay_list)
    return datax, datay



# Read images and labels from train and test directories
trainx, trainy = read_images(train_directory)
testx, testy = read_images(test_directory)

print(f"Train data shape: {trainx.shape}, Train labels shape: {trainy.shape}")
print(f"Test data shape: {testx.shape}, Test labels shape: {testy.shape}")

import numpy as np
import matplotlib.pyplot as plt

def visualize_samples(datax, datay, dataset_name):
    """
    Visualizes 2 images from each class in the dataset along with their labels.

    Parameters:
    - datax: numpy array of images (shape: [num_samples, height, width, channels])
    - datay: numpy array of labels corresponding to the images
    - dataset_name: string, name of the dataset (e.g., "Training Set")

    """
    unique_labels = np.unique(datay)
    num_classes = len(unique_labels)
    print("Number of classes in this dataset are", len(unique_labels))
    samples_per_class = proto_samples_per_class  # Number of images to display per class

    # Calculate the number of rows and columns for the subplot grid
    total_plots = num_classes * samples_per_class
    cols = samples_per_class
    rows = num_classes

    plt.figure(figsize=(samples_per_class * 3, num_classes * 3))

    for i, label in enumerate(unique_labels):
        # Get indices of images with the current label
        indices = np.where(datay == label)[0]
        # Select up to 'samples_per_class' indices
        selected_indices = indices[:samples_per_class]
        for j, idx in enumerate(selected_indices):
            img = datax[idx]
            # Rescale image if pixel values are in [0, 1]
            if img.max() <= 1.0:
                img = (img * 255).astype(np.uint8)
            else:
                img = img.astype(np.uint8)
            # Determine subplot position
            plt_idx = i * samples_per_class + j + 1
            plt.subplot(rows, cols, plt_idx)
            # Handle grayscale images
            if img.ndim == 2 or img.shape[-1] == 1:
                plt.imshow(img.squeeze(), cmap='gray')
            else:
                plt.imshow(img)
            plt.axis('off')
            plt.title(f"Label: {label}", fontsize=8)
    plt.suptitle(f"{dataset_name} Samples", fontsize=80)
    plt.tight_layout(rect=[0, 0, 1, 0.95])
    plt.show()

# Visualize samples from the training set
visualize_samples(trainx, trainy, "Training Set")

# Visualize samples from the test set
# visualize_samples(testx, testy, "Test Set")

def extract_sample(n_way, n_support, n_query, datax, datay):
    """
    Picks random sample of size n_support+n_querry, for n_way classes
    Args:
      n_way (int): number of classes in a classification task
      n_support (int): number of labeled examples per class in the support set
      n_query (int): number of labeled examples per class in the query set
      datax (np.array): dataset of images
      datay (np.array): dataset of labels
    Returns:
      (dict) of:
        (torch.Tensor): sample of images. Size (n_way, n_support+n_query, (dim))
        (int): n_way
        (int): n_support
        (int): n_query
    """
    sample = []
    K = np.random.choice(np.unique(datay), n_way, replace=False)
    for cls in K:
        datax_cls = datax[datay == cls]
        perm = np.random.permutation(datax_cls)
        sample_cls = perm[:(n_support+n_query)]
        sample.append(sample_cls)

    sample = np.array(sample)
    sample = tf.convert_to_tensor(sample, dtype=tf.float32)

    return({
          'images': sample,
          'n_way': n_way,
          'n_support': n_support,
          'n_query': n_query
          })

# sample_example = extract_sample(10, 5, 5, trainx, trainy)
# sample_example['images'].shape

import matplotlib.pyplot as plt
import tensorflow as tf

def display_images_grid(sample):
    """
    Displays all images from the sample in a grid classwise
    Args:
        sample (tf.Tensor): Tensor of images with shape [8, 10, 3, 32, 32]
    """
    # Ensure the sample is a TensorFlow tensor
    sample = tf.convert_to_tensor(sample)

    # Determine the number of classes and images per class
    num_classes = sample.shape[0]
    images_per_class = sample.shape[1]

    # Create a figure to display images in a grid
    fig, axs = plt.subplots(num_classes, images_per_class, figsize=(images_per_class, num_classes))

    # Display images classwise
    for i in range(num_classes):
        for j in range(images_per_class):
            image = sample[i, j]
            image = tf.transpose(image, perm=[0, 1, 2]).numpy().astype(np.uint8)
            axs[i, j].imshow(image)
            axs[i, j].axis('off')

    plt.tight_layout()
    plt.show()

# Example usage with TensorFlow tensors
# Assuming sample_example['images'] is a TensorFlow tensor with shape [8, 10, 3, 32, 32]
# sample_example = extract_sample(14, 5, 5, trainx, trainy)
# imags = tf.convert_to_tensor(sample_example['images'])
# display_images_grid(imags)

n_channels = 3

depth=28
width=2
dropout_rate=0.3
img_size = (128, 128)

base_model = make_feat_extractor(input_shape=(img_size[0], img_size[1], n_channels),
                                              num_classes=14,
                                              depth=depth, width=width, top = True,
                                              dropout_rate=dropout_rate, model_name='wide-resnet-ova')

# base_model.load_weights("/home/szt/ProtoNet_Inference/ProtoKD_Extension/DrAakur_model/125_10Shot_Ova_OnlyProto.ckpt")
base_model = Model(inputs=base_model.input, outputs=base_model.layers[-2].output)

def conv_model(model_name):

    if model_name == 'WideResNet':

        inputs = tf.keras.Input(shape=(128, 128, 3))
        x = tf.keras.applications.resnet50.preprocess_input(inputs)
        outputs = base_model(x)

    model_ = tf.keras.Model(inputs, outputs)

    return model_

model = conv_model('WideResNet')
model.summary()

def euclidean_distance(a, b):
    """
    Computes euclidean distance btw x and y
    Args:
      a (Query Tensor): shape (N, D). N usually n_way*n_query
      b (Proto Tensor): shape (M, D). M usually n_way
    Returns:
      Tensor: shape(N, M). For each query, the distances to each centroid
    """
    N, D = tf.shape(a)[0], tf.shape(a)[1]
    M = tf.shape(b)[0]
    a = tf.tile(tf.expand_dims(a, axis=1), (1, M, 1))
    b = tf.tile(tf.expand_dims(b, axis=0), (N, 1, 1))
    return tf.reduce_mean(tf.square(a - b), axis=2)

def calculate_loss(log_p_y, n_way, n_supp):
    temp = tf.Variable([])

    for i in range(0,n_way):
        for j in range(0,n_supp):
            temp = tf.experimental.numpy.append(temp, tf.gather_nd(log_p_y,indices=[[i,j,i]]))

    temp = tf.stack(temp, axis=0)
    return tf.reduce_mean(temp)

def calculate_acc(a_max_mat):
    n_way = a_max_mat.shape[0]        #Number of Classes
    n_support = a_max_mat.shape[1]    #Number of Supporting samples
    row = [1 for t in range(n_support)]
    temp = tf.convert_to_tensor(np.array([np.array(row)*i for i in range(n_way)]))
    bool_mat = tf.cast(tf.math.equal(temp,a_max_mat), dtype=tf.float32)

    return tf.reduce_mean(bool_mat)

class ProtoNet(Model):
    def __init__(self, model):
        """
        Args:
            encoder : CNN encoding the images in sample
            n_way (int): number of classes in a classification task
            n_support (int): number of labeled examples per class in the support set
            n_query (int): number of labeled examples per class in the query set
        """
        super(ProtoNet, self).__init__()
        self.model = model

    def set_forward_loss(self, sample):
        """
        Computes loss, accuracy and output for classification task
        Args:
            sample (Tensor): shape (n_way, n_support+n_query, (dim))
        Returns:
            Tensor: shape(2), loss, accuracy and y_hat
        """
        sample_images = sample['images']
        # print("Sample Images in forward Loss",sample_images.shape)
        n_way = sample['n_way']
        n_support = sample['n_support']
        n_query = sample['n_query']


        x_support = sample_images[:, :n_support]

        x_query = sample_images[:, n_support:]

        x_support = tf.reshape(x_support, (x_support.shape[0]*x_support.shape[1], x_support.shape[2],
                                           x_support.shape[3], x_support.shape[4]))

        x_query = tf.reshape(x_query, (x_query.shape[0]*x_query.shape[1], x_query.shape[2],
                                           x_query.shape[3], x_query.shape[4]))

        z_support = self.model(x_support)
        print("supp",z_support.shape)
        print(z_support)
        z_query = self.model(x_query)

        z_dim = z_support.shape[-1]
        z_support = tf.reshape(z_support, shape=[n_way,n_support,z_dim])

        z_proto = tf.reduce_mean(z_support, axis=1)

        dists = euclidean_distance(z_query, z_proto)

        log_p_y = tf.reshape(tf.nn.log_softmax(-dists), [n_way, n_query, -1])
        loss_val =  calculate_loss(-log_p_y, n_way, n_support)

        y_hat = tf.argmax(log_p_y, axis=-1)    #Predictions

        acc_val = calculate_acc(y_hat)

        return loss_val, {
            'loss': loss_val,
            'acc': acc_val,
            'y_hat': y_hat
            }

def test(model, test_x, test_y, n_way, n_support, n_query, test_episode):
    """
    Tests the protonet
    Args:
      model: trained model
      test_x (np.array): images of testing set
      test_y (np.array): labels of testing set
      n_way (int): number of classes in a classification task
      n_support (int): number of labeled examples per class in the support set
      n_query (int): number of labeled examples per class in the query set
      test_episode (int): number of episodes to test on
    """
    running_loss = 0.0
    running_acc = 0.0
    for episode in range(test_episode):
        # print("Testing episode number", episode)
        sample = extract_sample(n_way, n_support, n_query, test_x, test_y)
        # print(sample['images'].shape)
        loss, output = model.set_forward_loss(sample)
        running_loss += output['loss']
        running_acc += output['acc']
    avg_loss = running_loss / test_episode
    avg_acc = running_acc / test_episode
    print('TEST results -- Loss: {:.4f} Acc: {:.4f}'.format(avg_loss, avg_acc))
    # return avg_acc
    return avg_acc, avg_loss

def train(pnet_model, optimizer, train_x, train_y, n_way, n_support, n_query, max_epoch, epoch_size):
    """
    Trains the protonet
    Args:
      model
      optimizer
      train_x (np.array): images of training set
      train_y(np.array): labels of training set
      n_way (int): number of classes in a classification task
      n_support (int): number of labeled examples per class in the support set
      n_query (int): number of labeled examples per class in the query set
      max_epoch (int): max epochs to train on
      epoch_size (int): episodes per epoch
    """

    epoch = 0
    test_acc_list = []
    test_loss_list = []
    acc_list = []
    loss_list = []
    test_x_axis_epochs = []


    while epoch < max_epoch:
        # epoch += 1
        running_loss = 0.0
        running_acc = 0.0
        for episode in range(epoch_size):
        # for episode in tnrange(epoch_size, desc="Epoch {:d} train".format(epoch+1)):
            sample = extract_sample(n_way, n_support, n_query, train_x, train_y)
            with tf.GradientTape() as tape:
                loss, output = pnet_model.set_forward_loss(sample)
                running_loss += output['loss']
                running_acc += output['acc']

            gradients = tape.gradient(loss, pnet_model.trainable_variables)
            optimizer.apply_gradients(zip(gradients, pnet_model.trainable_variables))
        epoch_loss = running_loss / epoch_size
        epoch_acc = running_acc / epoch_size
        print('Epoch {:d} -- Loss: {:.4f} Acc: {:.4f}'.format(epoch+1,epoch_loss, epoch_acc))
        acc_list.append(epoch_acc)
        loss_list.append(epoch_loss)

        if (epoch+1) % 10 == 0:
            test_episode = 1000
            test_acc, test_loss = test(pnet_model, testx, testy, n_way, n_support, n_query, test_episode)
            test_acc_list.append(test_acc)
            test_loss_list.append(test_loss)

            test_x_axis_epochs.append(epoch)
            if epoch+1>=50:
                print(f"Model saved to Ova_Results/{proto_samples_per_class}_Ablation_Results/Epoch_{epoch}_{model_name}_weights.h5")
                pnet_model.model.save(f'Ova_Results/{proto_samples_per_class}_Ablation_Results/Epoch_{epoch}_{model_name}_weights.h5')

        epoch += 1

    # Save the losses and accuracies
    filename = f'Ova_Results/{proto_samples_per_class}_Ablation_Results/{n_support}_{model_name}.txt'
    with open(filename, 'w') as f:
        f.write('Training Accuracy\n')
        for acc in acc_list:
            f.write(f'{acc}\n')

        f.write('Testing Accuracy\n')
        for test_acc in test_acc_list:
            f.write(f'{test_acc}\n')

        f.write('Training Loss\n')
        for loss in loss_list:
            f.write(f'{loss}\n')

        f.write('Testing Loss\n')
        for test_loss in test_loss_list:
            f.write(f'{test_loss}\n')

        # Write the best test accuracy
        best_test_acc = max(test_acc_list)
        f.write(f'\nBest Test Accuracy: {best_test_acc:.4f}\n')

    fg = Figure()
    ax = fg.gca()
    ax.set_xlim([0, epoch])
    ax.plot(acc_list, label = "Training Accuracy")
    ax.plot(test_x_axis_epochs, test_acc_list, label = "Testing Accuracy")
    fg.legend(loc = 'lower center')
    ax.xaxis.set_major_locator(MaxNLocator(integer=True))
    ax.set_title('Accuracy {}-samples per class {}-way {}-shot'.format(proto_samples_per_class, n_way, n_support), fontsize=16)
    fg.savefig(f"Ova_Results/{proto_samples_per_class}_Ablation_Results/Accuracy Plot {n_way}_{n_support}_{model_name}-shot.png")

    # pnet_model.model.save(f'Ova_Results/{n_support}_Ablation_Results/{n_way}_{n_support}_{model_name}_weights.h5')

    return acc_list, loss_list, test_acc_list, test_loss_list

%%time
# model_name = 'MobileNet'
model_name ='WideResNet'
model = conv_model(model_name)
proto = ProtoNet(model)

optimizer = tf.keras.optimizers.Adam(0.00001, beta_1=0.9, beta_2=0.98,
                                         epsilon=1e-9)

n_way = len(all_classes)
n_support =5
n_query = 5

train_x = trainx
train_y = trainy

max_epoch = 100
epoch_size = 50

train(proto, optimizer, train_x, train_y, n_way, n_support, n_query, max_epoch, epoch_size)
